{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3685,"sourceType":"datasetVersion","datasetId":2190}],"dockerImageVersionId":29852,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Linear regression (predicting a continuous value):\n\n*** Question:**\n>     CalCOFI data: Over 60 years of oceanographic data: Is there a relationship between water salinity & water temperature? Can you predict the water temperature based on salinity?","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nimport operator\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bottle = pd.read_csv(\"../input/calcofi/bottle.csv\")\nbottle.head(2)","metadata":{"_cell_guid":"","_uuid":"","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bottle.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract 2 columns 'T_degC','Salnty' for pure and better showing\nbottle_df = bottle[['T_degC','Salnty']]\n\n# And called again\nbottle_df.columns = ['Temperature', 'Salinity']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bottle_df = bottle_df[:][:500]      # lets take limit for speed regression calculating\nbottle_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See picture with scatter or plot method\n\n# sns.lmplot(x=\"Salinity\", y=\"Temperature\", data=bottle_df, order=2, ci=None);\nsns.pairplot(bottle_df, kind=\"reg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# see how many null values we have\n\nbottle_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop NaN or missing input numbers\n\nbottle_df.fillna(method='ffill', inplace=True)\n#bottle_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features chose\n\nX = np.array(bottle_df['Salinity']).reshape(-1, 1)\ny = np.array(bottle_df['Temperature']).reshape(-1, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data as %20 is test and %80 is train set\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.Linear Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlin_df = LinearRegression()  \nlin_df.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = lin_df.predict(X_test)                                     # Predict Linear Model\naccuracy_score = lin_df.score(X_test, y_test)                       # Accuracy score\nprint(\"Linear Regression Model Accuracy Score: \" + \"{:.1%}\".format(accuracy_score))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error,r2_score\n\nprint(\"R2 Score: \" +\"{:.3}\".format(r2_score(y_test, y_pred)));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finally draw figure of Linear Regression Model\n\nplt.scatter(X_test, y_test, color='r')\nplt.plot(X_test, y_pred, color='g')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Multiple Linear Regression","metadata":{}},{"cell_type":"code","source":"mlin_df = LinearRegression()\nmlin_df = mlin_df.fit(X_train, y_train)\nmlin_df.intercept_       # constant b0\nmlin_df.coef_            # variable coefficient","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = mlin_df.predict(X_train)                                      # predict Multi linear Reg model\nrmse = np.sqrt(mean_squared_error(y_train, mlin_df.predict(X_train)))\nprint(\"RMSE Score for Test set: \" +\"{:.2}\".format(rmse))\nprint(\"R2 Score for Test set: \" +\"{:.3}\".format(r2_score(y_train, y_pred)));      # this is test error score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1.Multiple Linear Regression Model Tunning","metadata":{}},{"cell_type":"code","source":"# cross validation method is giving better and clear result\n\ncross_val_score(mlin_df, X, y, cv=10, scoring = 'r2').mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlin_df.score(X_train, y_train)      # r2 value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.sqrt(-cross_val_score(mlin_df, \n                X_train, \n                y_train, \n                cv=10, \n                scoring = 'neg_mean_squared_error')).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finally draw figure of Multiple Linear Regression Model\n\nplt.scatter(X_train, y_train, s=100)\n\n# sort the values of x before line plot\nsort_axis = operator.itemgetter(0)\nsorted_zip = sorted(zip(X_train,y_pred), key=sort_axis)\nX_test, y_pred = zip(*sorted_zip)\nplt.plot(X_train, y_train, color='g')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This was just for train set and you can also do for test set.","metadata":{}},{"cell_type":"markdown","source":"# 3.Polynomial Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\n\npoly_df = PolynomialFeatures(degree = 4)\ntransform_poly = poly_df.fit_transform(X_train)\n\nlinreg2 = LinearRegression()\nlinreg2.fit(transform_poly,y_train)\n\npolynomial_predict = linreg2.predict(transform_poly)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_train,polynomial_predict))\nr2 = r2_score(y_train,polynomial_predict)\nprint(\"RMSE Score for Test set: \" +\"{:.2}\".format(rmse))\nprint(\"R2 Score for Test set: \" +\"{:.2}\".format(r2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(X_train, y_train, s=50)\n# sort the values of x before line plot\nsort_axis = operator.itemgetter(0)\nsorted_zip = sorted(zip(X_train,polynomial_predict), key=sort_axis)\nX_train, polynomial_predict = zip(*sorted_zip)\nplt.plot(X_train, polynomial_predict, color='m')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This was just for train set and you can also do for test set.","metadata":{}},{"cell_type":"markdown","source":"# 4.Decision Tree Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndt_reg = DecisionTreeRegressor()          # create  DecisionTreeReg with sklearn\ndt_reg.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_predict = dt_reg.predict(X_train)\n#dt_predict.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(X_train,y_train, color=\"red\")                           # scatter draw\nX_grid = np.arange(min(np.array(X_train)),max(np.array(X_train)), 0.01)  \nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.plot(X_grid,dt_reg.predict(X_grid),color=\"g\")                 # line draw\nplt.xlabel(\"Temperature\")\nplt.ylabel(\"Salinity\")\nplt.title(\"Decision Tree Model\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_train,dt_predict))\nr2 = r2_score(y_train,dt_predict)\nprint(\"RMSE Score for Test set: \" +\"{:.2}\".format(rmse))\nprint(\"R2 Score for Test set: \" +\"{:.2}\".format(r2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This was just for train set and you can also do for test set.","metadata":{}},{"cell_type":"markdown","source":"# 5.Random Forest Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrf_reg = RandomForestRegressor(n_estimators=5, random_state=0)\nrf_reg.fit(X_train,y_train)\nrf_predict = rf_reg.predict(X_train)\n#rf_predict.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(X_train,y_train, color=\"red\")                           # scatter draw\nX_grid = np.arange(min(np.array(X_train)),max(np.array(X_train)), 0.01)  \nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.plot(X_grid,rf_reg.predict(X_grid),color=\"b\")                 # line draw\nplt.xlabel(\"Temperature\")\nplt.ylabel(\"Salinity\")\nplt.title(\"Decision Tree Model\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_train,rf_predict))\nr2 = r2_score(y_train,rf_predict)\nprint(\"RMSE Score for Test set: \" +\"{:.2}\".format(rmse))\nprint(\"R2 Score for Test set: \" +\"{:.2}\".format(r2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This was just for train set and you can also do for test set.","metadata":{}},{"cell_type":"markdown","source":"**Result:** When we revise 5 models, best one is Polynomial Regression Model with %92 accuracy score.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}